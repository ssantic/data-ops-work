


Assignment Doc
https://docs.google.com/document/d/e/2PACX-1vROrMMnQEYjRZqGnZnzzkY3b43vCdrtwc4_DMyRpMJr5UbTst4OmP8AhqbcaQjsr734G745-Qro6Tp7/pub?urp=gmail_link



AWS REGION: eu-central-1
https://eu-central-1.console.aws.amazon.com/ec2/v2/home?region=eu-central-1#Home:


Connect to instance
open command prompt

ssh -i "airflow_europe_region.pem" ubuntu@35.159.32.72


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Setup Docker on EC2 Starts
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
https://docs.docker.com/engine/install/ubuntu/

1.
sudo apt-get update
sudo apt-get install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release
Type Y for Yes

2.
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

3.
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

4.
sudo apt-get update

5.
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin
Type Y for Yes

6. Test run docker hello-world
sudo docker run hello-world


https://docs.docker.com/engine/install/linux-postinstall/
(Run docker without sudo command)

7.
sudo groupadd docker
sudo usermod -aG docker $USER
newgrp docker
docker run hello-world

8.
Install Docker-Compose also.
sudo apt install docker-compose

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Setup Docker on EC2 Ends
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Setup Airflow on EC2 Starts
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.3.0/docker-compose.yaml'


mkdir -p ./dags ./logs ./plugins
echo -e "AIRFLOW_UID=$(id -u)" > .env
AIRFLOW_UID=50000
docker-compose up airflow-init
docker-compose up


ENDPOINT_URL="http://localhost:8080/"
curl -X GET  \
    --user "airflow:airflow" \
    "${ENDPOINT_URL}/api/v1/pools"



Add Inbound rule of http and tcp 8080 in EC2 security group.



ENDPOINT_URL="http://3.72.19.169:8080/"
curl -X GET  \
    --user "airflow:airflow" \
    "${ENDPOINT_URL}/api/v1/pools"


To stop airflow and delete all containers
docker-compose down --volumes --rmi all
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Setup Airflow on EC2 Ends
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
To connect to EC2 instance, 


=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

Before Stopping EC2.
Execute : 
docker-compose down --volumes --rmi all

After starting EC2
Execute : 
docker-compose up airflow-init
docker-compose up

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Go to the pem file airflow_europe_region.pem
0. cd C:\Users\Srdjan\OneDrive\Desktop\dataops-assignemnt\airflow_assignment

Public IP: 18.185.148.55, (It will change on stop and start of EC2 instance)

if you are on ubuntu, open terminal and: 
1. chmod 400 airflow_europe_region.pem
2. ssh -i "airflow_europe_region.pem" ubuntu@18.185.148.55



=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=


Add Steps to create Airflow Variable 
key: aws_authorization
value:
{
    "AWS_ACCESS_KEY_ID":"############",
    "AWS_SECRET_ACCESS_KEY":"##########",
    "AWS_DEFAULT_REGION":"eu-central-1"
}

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Download dag file from S3 to EC2.
Prerequisite: Install AWS CLI if not exists.

export AWS_ACCESS_KEY_ID=############
export AWS_SECRET_ACCESS_KEY=###########
export AWS_DEFAULT_REGION=eu-central-1

aws s3 cp s3://covid-19-mathdroid/covid_19_data_store.py ~/dags/
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=


